Few selected papers from NeurIPS2019 conference based on my interests.
I will update the list with breif deatils for each paper based on my reading progress.


1. Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation

2. Zero-shot Learning via Simultaneous Generating and Learning

3. TensorPipe: Easy Scaling with Micro-Batch Pipeline Parallelism

4. Meta-Learning with Implicit Gradients

5. Deep ReLU Networks Have Surprisingly Few Activation Patterns

6. Zero-Shot Semantic Segmentation

7. NAT: Neural Architecture Transformer for Accurate and Compact Architectures

8. Deep Learning without Weight Transport

9. Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence

10. Neuron Communication Networks

11. Fine-grained Optimization of Deep Neural Networks

12. Multi-View Reinforcement Learning

13. Efficient Meta Learning via Minibatch Proximal Update

14. Positional Normalization

15. Self-Supervised Generalisation with Meta Auxiliary Learning

16. Meta-Learning Representations for Continual Learning

17. Channel Gating Neural Networks

18. XNAS: Neural Architecture Search with Expert Advice

19. Real-Time Reinforcement Learning

20. Training Language GANs from Scratch

21. Fast Efficient Hyperparameter Tuning for Policy Gradient Methods

22. Learning to Predict Without Looking Ahead: World Models Without Forward Prediction

23. XLNet: Generalized Autoregressive Pretraining for Language Understanding

24. Neural Machine Translation with Soft Prototype

25. Single-Model Uncertainties for Deep Learning

26. Large Scale Structure of Neural Network Loss Landscapes

27. Competitive Gradient Descent

28. Online Normalization for Training Neural Networks

29. Better Transfer Learning Through Inferred Successor Maps

30. Lookahead Optimizer: k steps forward, 1 step back

31. A Benchmark for Interpretability Methods in Deep Neural Networks

32. Learning to Learn By Self-Critique

33. Levenshtein Transformer

34. Meta Architecture Search

35. MetaInit: Initializing learning by learning to initialize

36. Episodic Memory in Lifelong Language Learning

37. Metalearned Neural Memory

38. Inducing brain-relevant bias in natural language processing models

39. Reinforcement Learning with Convex Constraints

40. Deep Leakage from Gradients

41. Self-attention with Functional Time Representation Learning
